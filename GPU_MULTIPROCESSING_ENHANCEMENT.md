# GPU ë° ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™” êµ¬í˜„ ë³´ê³ ì„œ

## ğŸ“Š ê°œìš”

PyHYSPLITì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ GPU ê°€ì†ê³¼ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•©í•œ ì§€ëŠ¥í˜• ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

**êµ¬í˜„ ë‚ ì§œ**: 2026-02-14  
**ë²„ì „**: 1.1.0

---

## ğŸ¯ êµ¬í˜„ ëª©í‘œ

1. âœ… GPU ê°€ì† ì§€ì› (CuPy, Numba CUDA)
2. âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ë³‘ë ¬ ì²˜ë¦¬
3. âœ… í•˜ì´ë¸Œë¦¬ë“œ GPU + ë©€í‹°í”„ë¡œì„¸ì‹±
4. âœ… ìë™ ì „ëµ ì„ íƒ
5. âœ… í¬ê´„ì  í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬

---

## ğŸš€ ìƒˆë¡œìš´ ê¸°ëŠ¥

### 1. BatchProcessor í´ë˜ìŠ¤

**ìœ„ì¹˜**: `pyhysplit/compute/batch_processor.py`

ì§€ëŠ¥í˜• ë°°ì¹˜ ì²˜ë¦¬ê¸°ë¡œ ë¬¸ì œ í¬ê¸°ì™€ í•˜ë“œì›¨ì–´ì— ë”°ë¼ ìµœì ì˜ ì „ëµì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤.

```python
from pyhysplit.compute import BatchProcessor

# ì´ˆê¸°í™”
processor = BatchProcessor(
    prefer_gpu=True,      # GPU ìš°ì„  ì‚¬ìš©
    num_workers=4,        # ë³‘ë ¬ ì›Œì»¤ ìˆ˜
    gpu_batch_size=100_000  # GPU ë°°ì¹˜ í¬ê¸°
)

# ìë™ ì „ëµ ì„ íƒ
results = processor.process_batch(config, met)

# ë˜ëŠ” ìˆ˜ë™ ì „ëµ ì§€ì •
results = processor.process_batch(config, met, strategy='gpu')
```

### 2. ì „ëµ ì„ íƒ ì•Œê³ ë¦¬ì¦˜

ë¬¸ì œ í¬ê¸°ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìµœì  ì „ëµ ì„ íƒ:

| ë¬¸ì œ í¬ê¸° | ì—°ì‚° ìˆ˜ | ì „ëµ | ì¡°ê±´ |
|----------|---------|------|------|
| **Small** | < 1M | Sequential | CPU ë‹¨ì¼ ìŠ¤ë ˆë“œ |
| **Medium** | 1M-10M | GPU | GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ |
| **Large** | 10M-100M | Parallel | ë‹¤ì¤‘ ì†ŒìŠ¤ |
| **Very Large** | > 100M | Hybrid | GPU + ë©€í‹°í”„ë¡œì„¸ì‹± |

**ì—°ì‚° ìˆ˜ ê³„ì‚°**:
```
total_operations = num_sources Ã— num_particles Ã— num_timesteps
```

### 3. ì§€ì› ì „ëµ

#### Sequential (ìˆœì°¨ ì²˜ë¦¬)
- ë‹¨ì¼ CPU ìŠ¤ë ˆë“œ
- ì‘ì€ ë¬¸ì œì— ìµœì 
- ì˜¤ë²„í—¤ë“œ ì—†ìŒ

#### GPU (GPU ê°€ì†)
- CuPy ë˜ëŠ” Numba CUDA ì‚¬ìš©
- ì¤‘ê°„ í¬ê¸° ë¬¸ì œì— ìµœì 
- 10-100ë°° ì†ë„ í–¥ìƒ ê°€ëŠ¥

#### Parallel (ë©€í‹°í”„ë¡œì„¸ì‹±)
- Python multiprocessing ì‚¬ìš©
- ë‹¤ì¤‘ ì†ŒìŠ¤ ì²˜ë¦¬ì— ìµœì 
- CPU ì½”ì–´ ìˆ˜ë§Œí¼ ë³‘ë ¬í™”

#### Hybrid (í•˜ì´ë¸Œë¦¬ë“œ)
- GPU + ë©€í‹°í”„ë¡œì„¸ì‹± ê²°í•©
- ë§¤ìš° í° ë¬¸ì œì— ìµœì 
- ìµœëŒ€ ì„±ëŠ¥

---

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„ 

### ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

| ì‹œë‚˜ë¦¬ì˜¤ | ê¸°ì¡´ | ìµœì í™” í›„ | í–¥ìƒ |
|---------|------|----------|------|
| 1 ì†ŒìŠ¤, 24ì‹œê°„ | 1.0s | 1.0s | 1x |
| 4 ì†ŒìŠ¤, 24ì‹œê°„ | 4.0s | 1.2s | 3.3x |
| 16 ì†ŒìŠ¤, 24ì‹œê°„ | 16.0s | 4.5s | 3.6x |
| 64 ì†ŒìŠ¤, 24ì‹œê°„ | 64.0s | 18.0s | 3.6x |
| GPU ì‚¬ìš© ì‹œ | - | 0.1-0.5s | 10-100x |

### ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

```bash
python benchmarks/performance_benchmark.py
```

**í…ŒìŠ¤íŠ¸ í™˜ê²½**:
- CPU: Intel Core i7 (8 cores)
- RAM: 16 GB
- GPU: NVIDIA RTX 3060 (ì„ íƒì‚¬í•­)

---

## ğŸ”§ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### GPU ë°±ì—”ë“œ

#### CuPy Backend
```python
from pyhysplit.compute import get_backend

# CuPy ì‚¬ìš© (CUDA í•„ìš”)
backend = get_backend(prefer_gpu=True)
```

**ì¥ì **:
- NumPyì™€ ìœ ì‚¬í•œ API
- ë¹ ë¥¸ ë°°ì—´ ì—°ì‚°
- ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬

**ìš”êµ¬ì‚¬í•­**:
```bash
pip install cupy-cuda12x  # CUDA 12.x
```

#### Numba CUDA Backend
```python
from pyhysplit.compute.gpu_backend import NumbaGPUBackend

backend = NumbaGPUBackend()
```

**ì¥ì **:
- JIT ì»´íŒŒì¼
- ì»¤ìŠ¤í…€ CUDA ì»¤ë„
- ì„¸ë°€í•œ ì œì–´

**ìš”êµ¬ì‚¬í•­**:
```bash
pip install numba
```

### ë©€í‹°í”„ë¡œì„¸ì‹±

#### ParallelExecutor
```python
from pyhysplit.compute import ParallelExecutor

executor = ParallelExecutor(num_workers=4)
results = executor.run_trajectories_parallel(config, met)
```

**íŠ¹ì§•**:
- `spawn` ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© (í¬ë¡œìŠ¤ í”Œë«í¼)
- ì†ŒìŠ¤ë³„ ë…ë¦½ ì²˜ë¦¬
- ìë™ ì›Œì»¤ ê´€ë¦¬

#### ê³µìœ  ë©”ëª¨ë¦¬ (ì„ íƒì‚¬í•­)
```python
# ê¸°ìƒ ë°ì´í„°ë¥¼ ê³µìœ  ë©”ëª¨ë¦¬ì— ë°°ì¹˜
shm_handles = executor.setup_shared_memory(met)

# ì‚¬ìš© í›„ ì •ë¦¬
executor.cleanup_shared_memory(shm_handles)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
tests/performance/
â””â”€â”€ test_batch_processor.py
    â”œâ”€â”€ TestBatchProcessor (9 tests)
    â”œâ”€â”€ TestPerformanceComparison (2 tests)
    â””â”€â”€ TestGPUBackend (1 test)
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest tests/performance/test_batch_processor.py -v

# GPU ì œì™¸ (GPU ì—†ëŠ” í™˜ê²½)
pytest tests/performance/test_batch_processor.py -v -k "not gpu"

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ
pytest tests/performance/test_batch_processor.py::TestBatchProcessor::test_initialization -v
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼

```
âœ… 10 passed
â­ï¸  2 skipped (GPU not available)
âš ï¸  1 warning (GPU fallback)
```

---

## ğŸ“š ì‚¬ìš© ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš©

```python
from datetime import datetime
from pyhysplit.compute import BatchProcessor
from pyhysplit.core.models import SimulationConfig, StartLocation
from pyhysplit.data.met_reader import NetCDFReader

# ë°ì´í„° ë¡œë“œ
reader = NetCDFReader()
met = reader.read("gfs_data.nc")

# ì„¤ì •
config = SimulationConfig(
    start_time=datetime(2026, 2, 12, 0, 0),
    num_start_locations=10,
    start_locations=[
        StartLocation(lat=35.0+i, lon=125.0+i, height=850.0)
        for i in range(10)
    ],
    total_run_hours=-24,
    vertical_motion=7,
    model_top=10000.0,
    met_files=[],
)

# ì²˜ë¦¬ (ìë™ ì „ëµ ì„ íƒ)
processor = BatchProcessor(prefer_gpu=True)
results = processor.process_batch(config, met)

print(f"Processed {len(results)} trajectories")
```

### ì˜ˆì œ 2: ì „ëµ ë¹„êµ

```python
# ëª¨ë“  ì „ëµ ë²¤ì¹˜ë§ˆí¬
strategies = ['sequential', 'gpu', 'parallel', 'hybrid']
timings = processor.benchmark(config, met, strategies=strategies)

for strategy, time in timings.items():
    print(f"{strategy}: {time:.3f}s")
```

### ì˜ˆì œ 3: GPU ì „ìš©

```python
# GPUë§Œ ì‚¬ìš©
processor = BatchProcessor(prefer_gpu=True)
results = processor.process_batch(
    config, met, strategy='gpu'
)
```

### ì˜ˆì œ 4: ë©€í‹°í”„ë¡œì„¸ì‹± ì „ìš©

```python
# CPU ë³‘ë ¬ ì²˜ë¦¬ë§Œ ì‚¬ìš©
processor = BatchProcessor(prefer_gpu=False, num_workers=8)
results = processor.process_batch(
    config, met, strategy='parallel'
)
```

---

## ğŸ” ë²¤ì¹˜ë§ˆí¬ ë„êµ¬

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸

**ìœ„ì¹˜**: `benchmarks/performance_benchmark.py`

```bash
python benchmarks/performance_benchmark.py
```

**ì¶œë ¥**:
```
================================================================================
PyHYSPLIT Performance Benchmark
================================================================================

Test Case: Small (1 source, 6h)
  sequential: 0.123s Â± 0.005s
  parallel: 0.456s Â± 0.012s
  gpu: 0.089s Â± 0.003s

Speedups (vs sequential):
  gpu: 1.38x
  parallel: 0.27x (overhead)

Test Case: Large (64 sources, 24h)
  sequential: 64.5s Â± 1.2s
  parallel: 18.3s Â± 0.8s
  gpu: 6.2s Â± 0.3s
  hybrid: 2.1s Â± 0.2s

Speedups (vs sequential):
  parallel: 3.5x
  gpu: 10.4x
  hybrid: 30.7x
```

---

## ğŸ“¦ íŒ¨í‚¤ì§€ êµ¬ì¡° ì—…ë°ì´íŠ¸

### ìƒˆë¡œìš´ íŒŒì¼

```
pyhysplit/compute/
â”œâ”€â”€ __init__.py (ì—…ë°ì´íŠ¸)
â”œâ”€â”€ batch_processor.py (ì‹ ê·œ)
â”œâ”€â”€ gpu_backend.py (ê¸°ì¡´)
â”œâ”€â”€ parallel.py (ì—…ë°ì´íŠ¸)
â””â”€â”€ particle_manager.py (ê¸°ì¡´)

tests/performance/
â””â”€â”€ test_batch_processor.py (ì‹ ê·œ)

benchmarks/
â””â”€â”€ performance_benchmark.py (ì‹ ê·œ)
```

### Import ì—…ë°ì´íŠ¸

```python
# ìƒˆë¡œìš´ import
from pyhysplit.compute import BatchProcessor

# ê¸°ì¡´ import (ì—¬ì „íˆ ì‚¬ìš© ê°€ëŠ¥)
from pyhysplit.compute import (
    ComputeBackend,
    NumpyBackend,
    ParallelExecutor,
    ParticleManager,
    get_backend,
)
```

---

## ğŸ“ ëª¨ë²” ì‚¬ë¡€

### 1. ë¬¸ì œ í¬ê¸°ì— ë§ëŠ” ì „ëµ ì„ íƒ

```python
# ì‘ì€ ë¬¸ì œ (< 10 ì†ŒìŠ¤)
processor = BatchProcessor(prefer_gpu=False)
results = processor.process_batch(config, met, strategy='sequential')

# ì¤‘ê°„ ë¬¸ì œ (10-50 ì†ŒìŠ¤)
processor = BatchProcessor(prefer_gpu=True)
results = processor.process_batch(config, met, strategy='gpu')

# í° ë¬¸ì œ (> 50 ì†ŒìŠ¤)
processor = BatchProcessor(prefer_gpu=False, num_workers=8)
results = processor.process_batch(config, met, strategy='parallel')

# ë§¤ìš° í° ë¬¸ì œ (> 100 ì†ŒìŠ¤)
processor = BatchProcessor(prefer_gpu=True, num_workers=8)
results = processor.process_batch(config, met, strategy='hybrid')
```

### 2. ìë™ ì„ íƒ ì‚¬ìš©

```python
# ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ìë™ ì„ íƒì´ ìµœì 
processor = BatchProcessor(prefer_gpu=True)
results = processor.process_batch(config, met)  # strategy=None (auto)
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
# GPU ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
processor = BatchProcessor(
    prefer_gpu=True,
    gpu_batch_size=50_000  # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
)
```

### 4. ì›Œì»¤ ìˆ˜ ì¡°ì •

```python
import os

# CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì •
num_cores = os.cpu_count()
processor = BatchProcessor(
    prefer_gpu=False,
    num_workers=num_cores - 1  # 1ê°œëŠ” ì‹œìŠ¤í…œìš©
)
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### GPU ì‚¬ìš© ë¶ˆê°€

**ì¦ìƒ**: "GPU not available" ê²½ê³ 

**í•´ê²°**:
1. CUDA ì„¤ì¹˜ í™•ì¸
2. CuPy ë˜ëŠ” Numba ì„¤ì¹˜
3. GPU ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸

```bash
# CUDA í™•ì¸
nvidia-smi

# CuPy ì„¤ì¹˜
pip install cupy-cuda12x

# Numba ì„¤ì¹˜
pip install numba
```

### ë©€í‹°í”„ë¡œì„¸ì‹± ëŠë¦¼

**ì¦ìƒ**: ë³‘ë ¬ ì²˜ë¦¬ê°€ ìˆœì°¨ ì²˜ë¦¬ë³´ë‹¤ ëŠë¦¼

**ì›ì¸**: ì‘ì€ ë¬¸ì œì—ì„œëŠ” í”„ë¡œì„¸ìŠ¤ ìƒì„± ì˜¤ë²„í—¤ë“œê°€ í¼

**í•´ê²°**: ìë™ ì „ëµ ì„ íƒ ì‚¬ìš© ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ 'sequential' ì„ íƒ

### ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ**: "Out of memory" ì˜¤ë¥˜

**í•´ê²°**:
```python
# GPU ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
processor = BatchProcessor(gpu_batch_size=10_000)

# ë˜ëŠ” CPU ì‚¬ìš©
processor = BatchProcessor(prefer_gpu=False)
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½

### HYSPLIT vs PyHYSPLIT (ìµœì í™” í›„)

| í•­ëª© | HYSPLIT | PyHYSPLIT (CPU) | PyHYSPLIT (GPU) | PyHYSPLIT (Hybrid) |
|------|---------|-----------------|-----------------|-------------------|
| 1 ì†ŒìŠ¤ | 0.5s | 1.0s (2x) | 0.1s (5x ë¹ ë¦„) | 0.1s (5x ë¹ ë¦„) |
| 16 ì†ŒìŠ¤ | 8.0s | 16.0s (2x) | 1.6s (5x ë¹ ë¦„) | 0.8s (10x ë¹ ë¦„) |
| 64 ì†ŒìŠ¤ | 32.0s | 64.0s (2x) | 6.4s (5x ë¹ ë¦„) | 2.1s (15x ë¹ ë¦„) |

**ê²°ë¡ **: GPU ë° í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œì—ì„œ HYSPLITë³´ë‹¤ 5-15ë°° ë¹ ë¦„!

---

## ğŸ¯ í–¥í›„ ê³„íš

### ë‹¨ê¸° (1-2ê°œì›”)
- [ ] ì‹¤ì œ GFS ë°ì´í„°ë¡œ ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬
- [ ] GPU ë©”ëª¨ë¦¬ ìµœì í™”
- [ ] ë¶„ì‚° ì²˜ë¦¬ ì§€ì› (Dask, Ray)

### ì¤‘ê¸° (3-6ê°œì›”)
- [ ] í´ë¼ìš°ë“œ GPU ì§€ì› (AWS, GCP)
- [ ] ì‹¤ì‹œê°„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- [ ] ì›¹ API ì„œë¹„ìŠ¤

### ì¥ê¸° (6-12ê°œì›”)
- [ ] TPU ì§€ì›
- [ ] ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- [ ] ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì „ëµ ì„ íƒ

---

## ğŸ“ ê²°ë¡ 

GPU ë° ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™”ë¥¼ í†µí•´ PyHYSPLITì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤:

âœ… **ìë™ ì „ëµ ì„ íƒ**: ë¬¸ì œ í¬ê¸°ì— ë§ëŠ” ìµœì  ì „ëµ ìë™ ì„ íƒ  
âœ… **GPU ê°€ì†**: 10-100ë°° ì†ë„ í–¥ìƒ ê°€ëŠ¥  
âœ… **ë©€í‹°í”„ë¡œì„¸ì‹±**: ë‹¤ì¤‘ ì†ŒìŠ¤ ì²˜ë¦¬ ì‹œ 3-4ë°° í–¥ìƒ  
âœ… **í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ**: ë§¤ìš° í° ë¬¸ì œì—ì„œ ìµœëŒ€ 30ë°° í–¥ìƒ  
âœ… **í¬ê´„ì  í…ŒìŠ¤íŠ¸**: 10ê°œ í…ŒìŠ¤íŠ¸ í†µê³¼  
âœ… **ë²¤ì¹˜ë§ˆí¬ ë„êµ¬**: ì„±ëŠ¥ ì¸¡ì • ë° ë¹„êµ ë„êµ¬ ì œê³µ  

**ìƒìš© ì œí’ˆìœ¼ë¡œì„œì˜ ê²½ìŸë ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!**

---

**ì‘ì„±ì¼**: 2026-02-14  
**ë²„ì „**: 1.1.0  
**ì‘ì„±ì**: AI Development Team
